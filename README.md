# Analysing the English-language Wikipedia dump dataset using Distributed Computing Techniques on GCP

Prepared the Wikipedia dump dataset by downloading, decompressing and loading it into Spark RDDs and DataFrames for efficient data processing and provided valuable insights into Wikipedia content and contributor behavior.

#### Credit
This is my code from an individual academic assignment given under the LSE ST446 coursework (2024); my work achieved the mark of **Distinction** in the assignment.
